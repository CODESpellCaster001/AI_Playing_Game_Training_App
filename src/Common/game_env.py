# src/Common/game_env.py
from collections import Counter
from stable_baselines3.common.env_util import make_atari_env
from stable_baselines3.common.vec_env import VecFrameStack
import cv2
import numpy as np
from scipy.stats import skew, kurtosis

def create_env(environment_name='Breakout-v4', n_envs=4, n_stack=4, seed=0):
    env = make_atari_env(environment_name, n_envs=n_envs, seed=seed)
    env.metadata['render_fps'] = 30
    env = VecFrameStack(env, n_stack=n_stack)
    return env

def create_eval_env(environment_name='Breakout-v4', n_envs=1, n_stack=4, seed=0):
    eval_env = make_atari_env(environment_name, n_envs=n_envs, seed=seed)
    eval_env.metadata['render_fps'] = 30
    eval_env = VecFrameStack(eval_env, n_stack=n_stack)
    return eval_env

# def record_env(env, model, video_path, video_fps=30, recording_time=60):
#     env.reset()
#     obs = env.reset()
#     done = np.array([False] * env.num_envs)
#     step = 0
#     max_steps = recording_time * video_fps
#
#     frame = env.render(mode='rgb_array')
#     height, width, _ = frame.shape
#     fourcc = cv2.VideoWriter_fourcc(*'XVID')
#     out = cv2.VideoWriter(video_path, fourcc, video_fps, (width, height))
#
#     while step < max_steps:
#         action, _ = model.predict(obs, deterministic=True)
#         obs, reward, done, info = env.step(action)
#         frame = env.render(mode='rgb_array')
#         out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))
#
#         if done.any():
#             obs = env.reset()
#
#         step += 1
#
#     out.release()
#     env.close()

def record_env(env, model, video_path, video_fps=30, recording_time=60, pass_threshold=5):
    """
    é€šç”¨ç‰ˆï¼šè·‘ä»»ä½• Gym çŽ¯å¢ƒï¼ˆåªè¦è£…äº† Monitor wrapperï¼è¿”å›ž episode infoï¼‰ï¼Œ
    é‡åˆ°ä¸€å±€ç»“æŸå°±è‡ªåŠ¨è®°å½•ä¸€å±€åˆ†æ•°ï¼Œä¸ç”¨å†™æ­»å‘½æ•°ã€‚
    """
    # ç¡®ä¿ env è¢« Monitor åŒ…äº†ä¸€å±‚ï¼Œè¿™æ · info[i] ä¼šæœ‰ 'episode'
    # å¦‚æžœä½ è¿˜æ²¡åŒ…ï¼š env = Monitor(env, './videos/', force=True)

    obs = env.reset()
    num_envs = getattr(env, 'num_envs', 1)
    step = 0
    max_steps = recording_time * video_fps

    # å‡†å¤‡è§†é¢‘å†™å…¥
    frame = env.render(mode='rgb_array')
    h, w, _ = frame.shape
    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    out = cv2.VideoWriter(video_path, fourcc, video_fps, (w, h))

    episode_scores = []

    while step < max_steps:
        action, _ = model.predict(obs, deterministic=True)
        obs, rewards, dones, infos = env.step(action)

        # æ¸²æŸ“å¹¶å†™å¸§
        frame = env.render(mode='rgb_array')
        out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))

        # æ£€æŸ¥ info é‡Œæœ‰æ²¡æœ‰ episode ç»“æŸçš„æ•°æ®
        # å¤š env æ—¶ infos æ˜¯åˆ—è¡¨ï¼›å• env æ—¶ç›´æŽ¥æ˜¯ dict
        if isinstance(infos, dict):
            infos = [infos]

        for info in infos:
            if 'episode' in info:
                # info['episode']['r'] æ˜¯è¿™ä¸€å±€çš„æ€» reward
                episode_scores.append(info['episode']['r'])

        # reset done çš„ env
        if dones.any() if num_envs > 1 else dones:
            new_obs = env.reset()
            obs = new_obs

        step += 1

    out.release()
    env.close()

    if not episode_scores:
        print("âš ï¸ æ²¡æœ‰å®Œæ•´è·‘å®Œä¸€å±€ï¼Œè¯•è¯•å»¶é•¿ recording_time æˆ–é™ä½Ž fpsã€‚")
        return

    scores = np.array(episode_scores)
    total_eps = len(scores)

    # åŸºç¡€ç»Ÿè®¡
    mean_score   = scores.mean()
    median_score = np.median(scores)
    max_score    = scores.max()
    min_score    = scores.min()
    var_score    = scores.var()
    std_score    = scores.std()

    # CV
    cv = std_score / mean_score if mean_score != 0 else float('nan')
    # ååº¦ & å³°åº¦
    sk = skew(scores)
    kt = kurtosis(scores)
    # æŽ’é™¤æœ€é«˜/æœ€ä½Ž
    trimmed = scores[(scores != max_score) & (scores != min_score)]
    var_trimmed, std_trimmed = (trimmed.var(), trimmed.std()) if len(trimmed) >= 2 else (float('nan'), float('nan'))
    # ä¼—æ•°
    mode_score, mode_count = Counter(scores).most_common(1)[0]
    # å‘½ä¸­çŽ‡ & è¾¾æ ‡çŽ‡
    nonzero_eps = np.count_nonzero(scores)
    accuracy = nonzero_eps / total_eps
    pass_count = np.sum(scores >= pass_threshold)
    pass_rate  = pass_count / total_eps

    # æ‰“å°
    print("ðŸ“Š æŽ¨ç†ç»Ÿè®¡ç»“æžœï¼š")
    print(f"  â€¢ å®Œæˆå±€æ•°ï¼š{total_eps}")
    print(f"  â€¢ æœ‰åˆ†å±€æ•°ï¼š{nonzero_eps}ï¼Œå‘½ä¸­çŽ‡ï¼š{accuracy:.2%}")
    print(f"  â€¢ é˜ˆå€¼ï¼š{pass_threshold}ï¼Œè¾¾æ ‡å±€æ•°ï¼š{pass_count}ï¼Œè¾¾æ ‡çŽ‡ï¼š{pass_rate:.2%}")
    print(f"  â€¢ å¹³å‡åˆ†ï¼š{mean_score:.2f}ï¼Œä¸­ä½æ•°ï¼š{median_score:.2f}")
    print(f"  â€¢ èŒƒå›´ï¼š[{min_score:.2f}, {max_score:.2f}]")
    print(f"  â€¢ åŽŸæ–¹å·®/æ ‡å‡†å·®ï¼š{var_score:.2f}/{std_score:.2f}")
    print(f"  â€¢ åŽ»æžç«¯åŽæ–¹å·®/æ ‡å‡†å·®ï¼š{var_trimmed:.2f}/{std_trimmed:.2f}")
    print(f"  â€¢ å˜å¼‚ç³»æ•° CVï¼š{cv:.2f}")
    print(f"  â€¢ ååº¦/å³°åº¦ï¼š{sk:.2f}/{kt:.2f}")
    print(f"  â€¢ ä¼—æ•°åˆ†ï¼š{mode_score:.2f}ï¼ˆ{mode_count} æ¬¡ï¼‰")

def create_single_env(environment_name='Breakout-v4', n_envs=1, n_stack=1, seed=0):
    env = make_atari_env(environment_name, n_envs=n_envs, seed=seed)
    env.metadata['render_fps'] = 30
    if n_stack > 0:
        env = VecFrameStack(env, n_stack=n_stack)
    return env

def record_fsm_env(env, fsm_agent, video_path, video_fps=30, recording_time=60):
    env.reset()
    state = env.reset()
    done = False
    step = 0
    max_steps = recording_time * video_fps

    frame = env.render(mode='rgb_array')
    height, width, _ = frame.shape
    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    out = cv2.VideoWriter(video_path, fourcc, video_fps, (width, height))

    while step < max_steps:
        action = fsm_agent.act(frame)
        state, reward, done, info = env.step(action)
        frame = env.render(mode='rgb_array')
        out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))

        if done:
            state = env.reset()

        step += 1

    out.release()
    env.close()
